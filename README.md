# doom rl

[StableBaselines3](https://stable-baselines3.readthedocs.io/en/master/index.html) implementations of PPO[1] on [ViZDoomGym](https://github.com/shakenes/vizdoomgym) wrapper.

## Examples

<img src="videos/2.gif" width="400" height="400" />

## References
[1] - Schulman & Co et al. (2017) Proximal Policy Optimization Algorithms. Available at: https://arxiv.org/abs/1707.06347 <br />
